# GPU instance running Ollama
OLLAMA_BASE_URL=http://<gpu-instance-ip>:11434

# WasmEdge runtime paths (output from setup-runtime.sh)
WASM_PYTHON_PATH=/opt/wasmedge-python/bin/python-3.11.1-wasmedge-aot.wasm
WASM_PYTHON_DIR=/opt/wasmedge-python

# Project paths
PLUGINS_DIR=./plugins/deployed
SDK_PATH=./backend/sdk/platform_sdk.py

# Limits
MAX_EXECUTION_TIME=30
MAX_PROMPT_LENGTH=4000
MAX_AI_CALLS_PER_EXECUTION=10

# Models (comma-separated, must match what Ollama has pulled)
ALLOWED_MODELS=llama3,llava,mistral

# Server
API_HOST=0.0.0.0
API_PORT=8000

